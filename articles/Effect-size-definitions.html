<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Effect size definitions and mathematical details • SingleCaseES</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Effect size definitions and mathematical details">
<meta property="og:description" content="SingleCaseES">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SingleCaseES</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.7.1.9999</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Effect-size-definitions.html">Effect size definitions and mathematical details</a>
    </li>
    <li>
      <a href="../articles/Using-SingleCaseES.html">Basic effect sizes calculations using SingleCaseES</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jepusto/SingleCaseES/" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Effect size definitions and mathematical
details</h1>
                        <h4 data-toc-skip class="author">James E.
Pustejovsky, Daniel M. Swan, and Man Chen</h4>
            
            <h4 data-toc-skip class="date">2023-07-27</h4>
      
      
      <div class="hidden name"><code>Effect-size-definitions.Rmd</code></div>

    </div>

    
    
<p>The SingleCaseES package provides R functions for calculating basic,
within-case effect size indices for single-case designs, including
several non-overlap measures and parametric effect size measures, and
for estimating the gradual effects model developed by <span class="citation">Swan &amp; Pustejovsky (<a href="#ref-Swan2018gradual" role="doc-biblioref">2018</a>)</span>. Estimation procedures for
standard errors and confidence intervals are provided for the subset of
effect sizes indices with known sampling distributions. This vignette
covers the mathematical definitions of the basic non-overlap and
parametric effect size measures, along with some details about how they
are estimated. <span class="citation">Parker, Vannest, &amp; Davis (<a href="#ref-parker2011effect" role="doc-biblioref">2011</a>)</span>
provides a review of the non-overlap measures, including worked examples
of the calculations. <span class="citation">Pustejovsky (<a href="#ref-pustejovsky2018procedural" role="doc-biblioref">2019</a>)</span> provides a critical review of
non-overlap measures and parametric effect sizes. However, neither of
these reviews include details about standard error calculations.</p>
<div class="section level2">
<h2 id="notation">Notation<a class="anchor" aria-label="anchor" href="#notation"></a>
</h2>
<p>All of the within-case effect size measures are defined in terms of a
comparison of observations between two phases (call them phase A and
phase B) within a single-case design. Let <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> denote the number of observations in
phase A and phase B, respectively. Let <span class="math inline">\(y^A_1,...,y^A_m\)</span> denote the observations
from phase A and <span class="math inline">\(y^B_1,...,y^B_n\)</span>
denote the observations from phase B.</p>
<p>The non-overlap effect size measures are all defined in terms of
ordinal comparisons between data points from phase A and data points
from phase B. It will therefore be helpful to have notation for the data
points from each phase, sorted in rank order. Thus, let <span class="math inline">\(y^A_{(1)},y^A_{(2)},...,y^A_{(m)}\)</span> denote
the values of the baseline phase data, sorted in increasing order, and
let <span class="math inline">\(y^B_{(1)},y^B_{(2)},...,y^B_{(n)}\)</span> denote
the values of the sorted treatment phase data.</p>
<p>The parametric effect size measures are all defined under a simple
model for the data-generating process, in which observations in phase A
are sampled from a distribution with constant mean <span class="math inline">\(\mu_A\)</span> and standard deviation <span class="math inline">\(\sigma_A\)</span>, while observations in phase B
are sampled from a distribution with constant mean <span class="math inline">\(\mu_B\)</span> and standard deviation <span class="math inline">\(\sigma_B\)</span>. Let <span class="math inline">\(\bar{y}_A\)</span> and <span class="math inline">\(\bar{y}_B\)</span> denote the sample means for
phase A and phase B, respectively. Let <span class="math inline">\(s_A\)</span> and <span class="math inline">\(s_B\)</span> denote the sample standard deviations
for phase A and phase B, respectively. Let <span class="math inline">\(z_{\alpha / 2}\)</span> denote the <span class="math inline">\(1 - \alpha / 2\)</span> critical value from a
standard normal distribution. Finally, we use <span class="math inline">\(\ln()\)</span> to denote the natural logarithm
function.</p>
</div>
<div class="section level2">
<h2 id="non-overlap-measures">Non-overlap measures<a class="anchor" aria-label="anchor" href="#non-overlap-measures"></a>
</h2>
<div class="section level3">
<h3 id="nap">NAP<a class="anchor" aria-label="anchor" href="#nap"></a>
</h3>
<p><span class="citation">Parker &amp; Vannest (<a href="#ref-parker2009improved" role="doc-biblioref">2009</a>)</span>
proposed non-overlap of all pairs (NAP) as an effect size index for use
in single-case research. NAP is defined in terms of all pair-wise
comparisons between the data points in two different phases for a given
case (i.e., a treatment phase versus a baseline phase). For an outcome
that is desirable to increase, NAP is the proportion of all such
pair-wise comparisons where the treatment phase observation exceeds the
baseline phase observation, with pairs that are exactly tied getting a
weight of 1/2. NAP is exactly equivalent to the modified Common Language
Effect Size <span class="citation">(<a href="#ref-Vargha2000critique" role="doc-biblioref">Vargha &amp; Delaney, 2000</a>)</span> and has been
proposed as an effect size index in other contexts too <span class="citation">(e.g., <a href="#ref-Acion2006probabilistic" role="doc-biblioref">Acion, Peterson, Temple, &amp; Arndt,
2006</a>)</span>.</p>
<p>NAP can be interpreted as an estimate of the probability that a
randomly selected observation from the B phase improves upon a randomly
selected observation from the A phase. For an outcome where increase is
desirable, the effect size parameter is</p>
<p><span class="math display">\[\theta = \text{Pr}(Y^B &gt; Y^A) + 0.5
\times \text{Pr}(Y^B = Y^A).\]</span></p>
<p>For an outcome where decrease is desirable, the effect size parameter
is</p>
<p><span class="math display">\[\theta = \text{Pr}(Y^B &lt; Y^A) + 0.5
\times \text{Pr}(Y^B = Y^A).\]</span></p>
<div class="section level4">
<h4 id="estimation">Estimation<a class="anchor" aria-label="anchor" href="#estimation"></a>
</h4>
<p>For an outcome where increase is desirable, calculate</p>
<p><span class="math display">\[q_{ij} = I(y^B_j &gt; y^A_i) + 0.5
I(y^B_j = y^A_i)\]</span> for <span class="math inline">\(i =
1,...,m\)</span> and <span class="math inline">\(j = 1,...,n\)</span>.
For an outcome where decrease is desirable, one would instead use</p>
<p><span class="math display">\[q_{ij} = I(y^B_j &lt; y^A_i) + 0.5
I(y^B_j = y^A_i).\]</span></p>
<p>The NAP effect size index is then calculated as</p>
<p><span class="math display">\[
\text{NAP} = \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n q_{ij}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="standard-errors">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors"></a>
</h4>
<p>The SingleCaseES package provides several different methods for
estimating the standard error of NAP. The default method is calculated
based on the exactly unbiased variance estimator described by <span class="citation">Sen (<a href="#ref-sen1967note" role="doc-biblioref">1967</a>; cf. <a href="#ref-mee1990confidence" role="doc-biblioref">Mee, 1990</a>)</span>, which assumes that the
observations are mutually independent and are identically distributed
within each phase. Let</p>
<p><span class="math display">\[
\begin{aligned}
Q_1 &amp;= \frac{1}{m n^2} \sum_{i=1}^m \left[\sum_{j=1}^n \left(q_{ij}
- \text{NAP}\right)\right]^2, \\
Q_2 &amp;= \frac{1}{m^2 n} \sum_{j=1}^n \left[\sum_{i=1}^m \left(q_{ij}
- \text{NAP}\right)\right]^2, \qquad \text{and} \\
Q_3 &amp;= \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n \left(q_{ij} -
\text{NAP}\right)^2.
\end{aligned}
\]</span></p>
<p>The SE is then calculated as</p>
<p><span class="math display">\[
SE_{\text{unbiased}} = \sqrt{\frac{\text{NAP}(1 - \text{NAP}) + n Q_1 +
m Q_2 - 2 Q_3}{(m - 1)(n - 1)}}.
\]</span></p>
<p>Another method for estimating a standard error was introduced by
<span class="citation">Hanley &amp; McNeil (<a href="#ref-Hanley1982meaning" role="doc-biblioref">1982</a>)</span>.
This standard error is calculated as</p>
<p><span class="math display">\[
SE_{\text{Hanley}} = \sqrt{\frac{1}{mn}\left(\text{NAP}(1 - \text{NAP})
+ (n - 1)Q_1 + (m - 1)Q_2\right)},
\]</span></p>
<p>with <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_2\)</span> defined as above. This standard error
is based on the same assumptions as the unbiased SE.</p>
<p>A limitation of <span class="math inline">\(SE_{unbiased}\)</span>
and <span class="math inline">\(SE_{Hanley}\)</span> is that they will
be equal to zero when there is complete non-overlap (i.e., when <span class="math inline">\(\text{NAP}\)</span> is equal to zero or equal to
one). In order to ensure a strictly positive standard error for NAP, the
SingleCaseES package calculates <span class="math inline">\(SE_{unbiased}\)</span> and <span class="math inline">\(SE_{Hanley}\)</span> using a truncation of NAP.
Specifically, the formulas are evaluated using</p>
<p><span class="math display">\[
\widetilde{\text{NAP}} = \text{max}\left\{\frac{1}{2 mn}, \
\text{min}\left\{\frac{2mn - 1}{2mn}, \ \text{NAP} \right\} \right\}
\]</span> in place of <span class="math inline">\(\text{NAP}\)</span>.</p>
<p>A final method for estimating a standard error is to work under the
null hypothesis that there is no effect—i.e., that the data points from
each phase are sampled from the same distribution. Under the null
hypothesis, the sampling variance of <span class="math inline">\(\text{NAP}\)</span> depends only on the number of
observations in each phase:</p>
<p><span class="math display">\[
SE_{\text{null}} = \sqrt{\frac{m + n + 1}{12 m n}}
\]</span> <span class="citation">(cf. <a href="#ref-Grissom2001review" role="doc-biblioref">Grissom &amp; Kim, 2001, p. 141</a>)</span>. If
null hypothesis is not true—that is, if the observations in phase B are
drawn from a different distribution than the observations in phase
A—then this standard error will tend to be too large.</p>
</div>
<div class="section level4">
<h4 id="confidence-interval">Confidence interval<a class="anchor" aria-label="anchor" href="#confidence-interval"></a>
</h4>
<p>A confidence interval for <span class="math inline">\(\theta\)</span>
can be calculated using a method proposed by Newcombe [<span class="citation">Newcombe (<a href="#ref-newcombe2006confidence" role="doc-biblioref">2006</a>)</span>; Method 5], which assumes that the
observations are mutually independent and are identically distributed
within each phase. Using a confidence level of <span class="math inline">\(100\% \times (1 - \alpha)\)</span>, the endpoints
of the confidence interval are defined as the values of <span class="math inline">\(\theta\)</span> that satisfy the equality</p>
<p><span class="math display">\[
(\text{NAP} - \theta)^2 = \frac{z^2_{\alpha / 2} h \theta (1 -
\theta)}{mn}\left[\frac{1}{h} + \frac{1 - \theta}{2 - \theta} +
\frac{\theta}{1 + \theta}\right],
\]</span></p>
<p>where <span class="math inline">\(h = (m + n) / 2 - 1\)</span> and
<span class="math inline">\(z_{\alpha / 2}\)</span> is <span class="math inline">\(1 - \alpha / 2\)</span> critical value from a
standard normal distribution. This equation is a fourth-degree
polynomial in <span class="math inline">\(\theta\)</span>, solved using
a numerical root-finding algorithm.</p>
</div>
</div>
<div class="section level3">
<h3 id="pnd">PND<a class="anchor" aria-label="anchor" href="#pnd"></a>
</h3>
<p><span class="citation">Scruggs, Mastropieri, &amp; Casto (<a href="#ref-scruggs1987quantitative" role="doc-biblioref">1987</a>)</span> proposed the percentage of
non-overlapping data (PND) as an effect size index for single-case
designs. For an outcome where increase is desirable, PND is defined as
the proportion of observations in the B phase that exceed the highest
observation from the A phase. For an outcome where decrease is
desirable, PND is the proportion of observations in the B phase that are
less than the lowest observation from the A phase.</p>
<p>This effect size does not have a stable parameter definition because
the magnitude of the maximum (or minimum) value from phase A depends on
the number of observations in the phase <span class="citation">(<a href="#ref-allison1994make" role="doc-biblioref">Allison &amp; Gorman,
1994</a>; <a href="#ref-pustejovsky2018procedural" role="doc-biblioref">Pustejovsky, 2019</a>)</span>.</p>
<div class="section level4">
<h4 id="estimation-1">Estimation<a class="anchor" aria-label="anchor" href="#estimation-1"></a>
</h4>
<p>For an outcome where increase is desirable,</p>
<p><span class="math display">\[
\text{PND} = \frac{1}{n} \sum_{j=1}^n I(y^B_j &gt; y^A_{(m)}),
\]</span></p>
<p>where <span class="math inline">\(y^A_{(m)}\)</span> is the maximum
value of <span class="math inline">\(y^A_1,...,y^A_m\)</span>. For an
outcome where decrease is desirable,</p>
<p><span class="math display">\[
\text{PND} = \frac{1}{n} \sum_{j=1}^n I(y^B_j &lt; y^A_{(1)}),
\]</span></p>
<p>where <span class="math inline">\(y^A_{(1)}\)</span> is the minimum
value of <span class="math inline">\(y^A_1,...,y^A_m\)</span>.</p>
<p>The sampling distribution of PND has not been described, and so
standard errors and confidence intervals are not available.</p>
</div>
</div>
<div class="section level3">
<h3 id="pem">PEM<a class="anchor" aria-label="anchor" href="#pem"></a>
</h3>
<p><span class="citation">Ma (<a href="#ref-ma2006alternative" role="doc-biblioref">2006</a>)</span> proposed the percent exceeding the
median, defined as the proportion of observations in phase B that
improve upon the median of phase A. <span class="citation">Ma (<a href="#ref-ma2006alternative" role="doc-biblioref">2006</a>)</span> did
not specify an effect size parameter corresponding to this index.
However, it would be reasonable to define the parameter as the
probability that a randomly selected observation from the B phase
represents an improvement over the median of the distribution of A phase
outcomes. Let <span class="math inline">\(\eta_A\)</span> denote the
median of the distribution of outcomes in phase A. For an outcome where
increase is desirable, the PEM parameter would then be</p>
<p><span class="math display">\[
\xi = \text{Pr}\left(Y_B &gt; \eta_A\right) + 0.5 \times
\text{Pr}\left(Y_B = \eta_A\right).
\]</span> For an outcome where decrease is desirable, it would be <span class="math display">\[
\xi = \text{Pr}\left(Y_B &lt; \eta_A\right) + 0.5 \times
\text{Pr}\left(Y_B = \eta_A\right).
\]</span></p>
<div class="section level4">
<h4 id="estimation-2">Estimation<a class="anchor" aria-label="anchor" href="#estimation-2"></a>
</h4>
<p>For an outcome where increase is desirable,</p>
<p><span class="math display">\[
\text{PEM} = \frac{1}{n}\sum_{j=1}^n \left[ I(y^B_j &gt; m_A) + 0.5
\times I(y^B_j = m_A) \right],
\]</span></p>
<p>where <span class="math inline">\(m_A =
\text{median}(y^A_1,...,y^A_m)\)</span>. For an outcome where decrease
is desirable,</p>
<p><span class="math display">\[
\text{PEM} = \frac{1}{n}\sum_{j=1}^n \left[ I(y^B_j &lt; y^A_{(1)}) +
0.5 \times I(y^B_j = m_A) \right].
\]</span></p>
<p>The sampling distribution of PEM has not been described, and so
standard errors and confidence intervals are not available.</p>
</div>
</div>
<div class="section level3">
<h3 id="pand">PAND<a class="anchor" aria-label="anchor" href="#pand"></a>
</h3>
<p>For an outcome where increase (decrease) is desirable, <span class="citation">Parker, Vannest, &amp; Davis (<a href="#ref-parker2011effect" role="doc-biblioref">2011</a>)</span>
defined PAND as the proportion of observations remaining after removing
the fewest possible number of observations from either phase so that the
highest remaining point from the baseline phase is less than the lowest
remaining point from the treatment phase (lowest remaining point from
the baseline phase is larger than the highest remaining point from the
treatment phase).</p>
<p>This effect size does not have a stable parameter definition because
its magnitude depends on the number of observations in each phase <span class="citation">(<a href="#ref-pustejovsky2018procedural" role="doc-biblioref">Pustejovsky, 2019</a>)</span>.</p>
<div class="section level4">
<h4 id="estimation-3">Estimation<a class="anchor" aria-label="anchor" href="#estimation-3"></a>
</h4>
<p>For an outcome where increase is desirable, PAND is calculated as</p>
<p><span class="math display">\[
\text{PAND} = \frac{1}{m + n} \max \left\{\left(i + j\right)
I\left(y^A_{(i)} &lt; y^B_{(n + 1 - j)}\right)\right\},
\]</span></p>
<p>where <span class="math inline">\(y^A_{(0)} = - \infty\)</span>,
<span class="math inline">\(y^B_{(n + 1)} = \infty\)</span>, and the
maximum is taken over the values <span class="math inline">\(0 \leq i
\leq m\)</span> and <span class="math inline">\(0 \leq j \leq
n\)</span>. For an outcome where decrease is desirable, PAND is
calculated as</p>
<p><span class="math display">\[
\text{PAND} = \frac{1}{m + n} \max \left\{\left(i + j\right)
I\left(y^A_{(m + 1 - i)} &gt; y^B_{(j)}\right)\right\},
\]</span></p>
<p>where <span class="math inline">\(y^A_{(m + 1)} = \infty\)</span>,
<span class="math inline">\(y^B_{(0)} = -\infty\)</span>, and the
maximum is taken over the values <span class="math inline">\(0 \leq i
\leq m\)</span> and <span class="math inline">\(0 \leq j \leq
n\)</span>.</p>
<p>The sampling distribution of PAND has not been described, and so
standard errors and confidence intervals are not available.</p>
</div>
</div>
<div class="section level3">
<h3 id="ird">IRD<a class="anchor" aria-label="anchor" href="#ird"></a>
</h3>
<p>The robust improvement rate difference is defined as the robust phi
coefficient corresponding to a certain <span class="math inline">\(2
\times 2\)</span> table that is a function of the degree of overlap
between the observations each phase <span class="citation">(<a href="#ref-parker2011effect" role="doc-biblioref">Parker, Vannest, &amp;
Davis, 2011</a>)</span>. This effect size does not have a stable
parameter definition because its magnitude depends on the number of
observations in each phase <span class="citation">(<a href="#ref-pustejovsky2018procedural" role="doc-biblioref">Pustejovsky,
2019</a>)</span>.</p>
<div class="section level4">
<h4 id="estimation-4">Estimation<a class="anchor" aria-label="anchor" href="#estimation-4"></a>
</h4>
<p>For notational convenience, let <span class="math inline">\(y^A_{(0)}
= y^B_{(0)} = -\infty\)</span> and <span class="math inline">\(y^A_{(m +
1)} = y^B_{(n + 1)} = \infty\)</span>. For an outcome where increase is
desirable, let <span class="math inline">\(\tilde{i}\)</span> and <span class="math inline">\(\tilde{j}\)</span> denote the values that maximize
the quantity</p>
<p><span class="math display">\[
\left(i + j\right) I\left(y^A_{(i)} &lt; y^B_{(n + 1 - j)}\right)
\]</span> for <span class="math inline">\(0 \leq i \leq m\)</span> and
<span class="math inline">\(0 \leq j \leq n\)</span>. For an outcome
where decrease is desirable, let <span class="math inline">\(\tilde{i}\)</span> and <span class="math inline">\(\tilde{j}\)</span> instead denote the values that
maximize the quantity</p>
<p><span class="math display">\[
\left(i + j\right) I\left(y^A_{(m + 1 - i)} &gt; y^B_{(j)}\right).
\]</span></p>
<p>Now calculate the <span class="math inline">\(2 \times 2\)</span>
table</p>
<p><span class="math display">\[
\begin{array}{|c|c|} \hline
m - \tilde{i} &amp; \tilde{j} \\ \hline
\tilde{i} &amp; n - \tilde{j} \\ \hline
\end{array}
\]</span></p>
<p><span class="citation">Parker, Vannest, &amp; Brown (<a href="#ref-parker2009improvement" role="doc-biblioref">2009</a>)</span>
proposed the <em>non-robust</em> improvement rate difference, which is
equivalent to the phi coefficient from this table. <span class="citation">Parker, Vannest, &amp; Davis (<a href="#ref-parker2011effect" role="doc-biblioref">2011</a>)</span>
proposed to instead use the <em>robust</em> phi coefficient, which
involves modifying the table so that the row- and column-margins are
equal. Robust IRD is thus equal to</p>
<p><span class="math display">\[
\text{IRD} = \frac{n - m - \tilde{i} - \tilde{j}}{2 n} - \frac{m + n -
\tilde{i} - \tilde{j}}{2 m}.
\]</span></p>
<p>Robust IRD is algebraically related to PAND as</p>
<p><span class="math display">\[
\text{IRD} = 1 - \frac{(m + n)^2}{2mn}\left(1 - \text{PAND}\right).
\]</span> Just as with PAND, the sampling distribution of robust IRD has
not been described, and so standard errors and confidence intervals are
not available.</p>
</div>
</div>
<div class="section level3">
<h3 id="tau">Tau<a class="anchor" aria-label="anchor" href="#tau"></a>
</h3>
<p>Tau is one of several effect sizes proposed by <span class="citation">Parker, Vannest, Davis, &amp; Sauber (<a href="#ref-parker2011combining" role="doc-biblioref">2011</a>)</span>
and known collectively as “Tau-U.” The basic estimator Tau does not make
any adjustments for time trends. For an outcome where increase is
desirable, the effect size parameter is</p>
<p><span class="math display">\[\tau = \text{Pr}(Y^B &gt; Y^A) -
\text{Pr}(Y^B &lt; Y^A)\]</span></p>
<p>(for an outcome where decrease is desirable, the effect size
parameter would have the opposite sign). This parameter is a simple
linear transformation of the NAP parameter <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\tau = 2 \theta - 1.\]</span></p>
<div class="section level4">
<h4 id="estimation-5">Estimation<a class="anchor" aria-label="anchor" href="#estimation-5"></a>
</h4>
<p>For an outcome where increase is desirable, calculate</p>
<p><span class="math display">\[w_{ij} = I(y^B_j &gt; y^A_i) - I(y^B_j
&lt; y^A_i)\]</span></p>
<p>For an outcome where decrease is desirable, one would instead use</p>
<p><span class="math display">\[w_{ij} = I(y^B_j &lt; y^A_i) - I(y^B_j
&gt; y^A_i).\]</span></p>
<p>The Tau effect size index is then calculated as</p>
<p><span class="math display">\[
\text{Tau} = \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n w_{ij} = 2 \times
\text{NAP} - 1.
\]</span></p>
</div>
<div class="section level4">
<h4 id="standard-errors-1">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors-1"></a>
</h4>
<p>Standard errors and confidence intervals for Tau are calculated using
transformations of the corresponding SEs and CIs for NAP. All of the
methods assume that the observations are mutually independent and are
identically distributed within each phase.</p>
<p>Standard errors for Tau are calculated as <span class="math inline">\(SE_{\text{Tau}} = 2 SE_{\text{NAP}}\)</span>,
where <span class="math inline">\(SE_{\text{NAP}}\)</span> is the
standard error for NAP calculated based on one of the available methods
(unbiased, Hanley, or null).</p>
</div>
<div class="section level4">
<h4 id="confidence-intervals">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals"></a>
</h4>
<p>The CI for <span class="math inline">\(\tau\)</span> is calculated
as</p>
<p><span class="math display">\[
[L_{\tau}, U_{\tau}] = [2 L_{\theta} - 1, 2 U_{\theta} - 1],
\]</span></p>
<p>where <span class="math inline">\(L_{\theta}\)</span> and <span class="math inline">\(U_{\theta}\)</span> are the lower and upper bounds
of the CI for <span class="math inline">\(\theta\)</span>, calculated
using a method proposed by <span class="citation">Newcombe (<a href="#ref-newcombe2006confidence" role="doc-biblioref">2006</a>)</span>.</p>
</div>
</div>
<div class="section level3">
<h3 id="tau-u">Tau-U<a class="anchor" aria-label="anchor" href="#tau-u"></a>
</h3>
<p>Tau-U is one of several effect sizes proposed by <span class="citation">Parker, Vannest, Davis, &amp; Sauber (<a href="#ref-parker2011combining" role="doc-biblioref">2011</a>)</span>.
The Tau-U variant is similar to Tau, but includes an adjustment term
that is a function of the baseline time trend. For an outcome where
increase is desirable, the index is calculated as Kendall’s <span class="math inline">\(S\)</span> statistic for the comparison between
the phase B data and the phase A data, plus Kendall’s <span class="math inline">\(S\)</span> statistic for the A phase observations,
scaled by the product of the number of observations in each phase.</p>
<p>This effect size does not have a stable parameter definition and its
feasible range depends on the number of observations in each phase <span class="citation">(<a href="#ref-tarlow2017improved" role="doc-biblioref">Tarlow, 2017</a>)</span>.</p>
<div class="section level4">
<h4 id="estimation-6">Estimation<a class="anchor" aria-label="anchor" href="#estimation-6"></a>
</h4>
<p>For an outcome where increase is desirable, calculate</p>
<p><span class="math display">\[w^{AB}_{ij} = I(y^B_j &gt; y^A_i) -
I(y^B_j &lt; y^A_i)\]</span></p>
<p>and</p>
<p><span class="math display">\[w^{AA}_{ij} = I(y^A_j &gt; y^A_i) -
I(y^A_j &lt; y^A_i)\]</span></p>
<p>For an outcome where decrease is desirable, one would instead use</p>
<p><span class="math display">\[w^{AB}_{ij} = I(y^B_j &lt; y^A_i) -
I(y^B_j &gt; y^A_i)\]</span></p>
<p>and</p>
<p><span class="math display">\[w^{AA}_{ij} = I(y^A_j &lt; y^A_i) -
I(y^A_j &gt; y^A_i).\]</span></p>
<p>The Tau-U effect size index is then calculated as</p>
<p><span class="math display">\[
\text{Tau-U} = \frac{1}{m n} \left(\sum_{i=1}^m \sum_{j=1}^n w^{AB}_{ij}
- \sum_{i=1}^{m - 1} \sum_{j=i + 1}^m w^{AA}_{ij}\right).
\]</span></p>
<p>The sampling distribution of Tau-U has not been described, and so
standard errors and confidence intervals are not available.</p>
</div>
</div>
<div class="section level3">
<h3 id="tau-bc">Tau-BC<a class="anchor" aria-label="anchor" href="#tau-bc"></a>
</h3>
<p><span class="citation">Tarlow (<a href="#ref-tarlow2017improved" role="doc-biblioref">2017</a>)</span> proposed to modify the Tau effect
size index by first adjusting the observations for a linear trend in the
A phase. The index can be calculated with or without conducting a
pre-test for significance of the A phase time trend. We provide two
approaches to calculate Tau no matter whether the baseline trend is
significant or not. The first approach is using Kendall’s rank
correlation (with adjustment for ties), as used in Tarlow (2017). The
second one is using Tau (non-overlap) index (without adjustment for
ties).</p>
<p>If the pre-test for A phase time trend is used, then slope of the
baseline trend is first tested using Kendall’s rank correlation. If the
baseline slope is significantly different from zero, the outcomes are
adjusted for baseline trend using Theil-Sen regression, and the
residuals from Theil-Sen regression are used to calculate the Kendall’s
rank correlation or Tau (non-overlap) index. If the baseline slope is
not significantly different from zero, then no baseline trend adjustment
is made, and the Tau-BC effect size is calculated using Kendall’s rank
correlation or Tau (non-overlap) index.</p>
<p>If the pre-test for A phase time trend is not used, then the outcomes
are adjusted for baseline trend using Theil-Sen regression, regardless
of whether the slope is significantly different from zero. The residuals
from Theil-Sen regression are then used to calculate the Kendall’s rank
correlation or Tau (non-overlap) index.</p>
<p>The formal definition of Tau-BC require positing a model for the time
trend in the data series. Thus, suppose that the outcomes can be
expressed in terms of a linear time trend and an error term:</p>
<p><span class="math display">\[
\begin{aligned}
y_i^A &amp;= \alpha + \beta (i) + \epsilon_i^A, \quad \text{for} \quad i
= 1,...,m \\
y_j^B &amp;= \alpha + \beta (m + j) + \epsilon_j^B \quad \text{for}
\quad j = 1,...,n.
\end{aligned}
\]</span> Within each phase, assume that the error terms are independent
and share a common distribution. The Tau-BC parameter can then be
defined as the Tau parameter for the distribution of the error terms,
or</p>
<p><span class="math display">\[
\tau_{BC} = \text{Pr}(\epsilon^B &gt; \epsilon^A) - \text{Pr}(\epsilon^B
&lt; \epsilon^A).
\]</span> An equivalent definition in terms of the outcome distributions
is</p>
<p><span class="math display">\[
\tau_{BC} = \text{Pr}\left[Y_j^B - \beta (m + j - i) &gt; Y_i^A \right]
- \text{Pr}\left[Y_j^B - \beta (m + j - i) &lt; Y_i^A\right]
\]</span> for <span class="math inline">\(i=1,...,m\)</span> and <span class="math inline">\(j = 1,...,n\)</span>.</p>
<div class="section level4">
<h4 id="estimation-7">Estimation<a class="anchor" aria-label="anchor" href="#estimation-7"></a>
</h4>
<p>Estimation of <span class="math inline">\(\tau_{BC}\)</span> entails
correcting the data series for the baseline slope <span class="math inline">\(\beta\)</span>. If using the baseline trend
pre-test, the null hypothesis of <span class="math inline">\(H_0: \beta
= 0\)</span> is first tested using Kendall’s rank correlation. If the
test is not significant, then set <span class="math inline">\(\hat\beta
= 0\)</span> and <span class="math inline">\(\hat\alpha = 0\)</span>. If
the test is significant or if the pre-test for baseline time trend is
not used, then the slope is estimated by Theil-Sen regression.
Specifically, we calculate the slope between every pair of observations
in the A phase: <span class="math display">\[
s_{hi} = \frac{y_i^A - y_h^A}{i - h}
\]</span> for <span class="math inline">\(i = 1,...,m - 1\)</span> and
<span class="math inline">\(h = i+1,...,m\)</span>. The overall slope
estimate is taken to be the median over all <span class="math inline">\(m(m - 1) / 2\)</span> slope pairs:</p>
<p><span class="math display">\[
\hat\beta = \text{median}\left\{s_{12},...,s_{(m-1)m}\right\}.
\]</span> The intercept term is estimated by taking the median
observation in the A phase after correcting for the estimated linear
time trend:</p>
<p><span class="math display">\[
\hat\alpha = \text{median}\left\{y_1^A - \hat\beta \times 1, \ y_2^A -
\hat\beta \times 2, ..., \ y_m^A - \hat\beta \times m\right\}.
\]</span> However, the intercept estimate is irrelevant for purposes of
estimating Tau-BC because the Tau estimator is a function of ranks and
is invariant to a linear shift of the data series.</p>
<p>After estimating the phase A time trend, <span class="math inline">\(\tau_{BC}\)</span> is estimated by de-trending the
full data series and calculating Kendall’s rank correlation or Tau
(non-overlap) on the de-trended observations. Specifically, set <span class="math inline">\(\hat\epsilon_i^A = y_i^A - \hat\beta (i) -
\hat\alpha\)</span> for <span class="math inline">\(i = 1,...,m\)</span>
and <span class="math inline">\(\hat\epsilon_j^B = y_j^B - \hat\beta (m
+ j) - \hat\alpha\)</span>. For an outcome where increase is desirable,
calculate <span class="math display">\[w^\epsilon_{ij} =
I\left(\hat\epsilon^B_j &gt; \hat\epsilon^A_i\right) -
I\left(\hat\epsilon^B_j &lt; \hat\epsilon^A_i\right)\]</span></p>
<p>or, for an outcome where decrease is desirable, calculate <span class="math display">\[w^\epsilon_{ij} = I\left(\hat\epsilon^B_j &lt;
\hat\epsilon^A_i\right) - I\left(\hat\epsilon^B_j &gt;
\hat\epsilon^A_i\right).\]</span></p>
<p>Tau-BC (non-overlap) is then estimated by <span class="math display">\[
\text{Tau}_{BC} = \frac{1}{m n} \sum_{i=1}^m \sum_{j=1}^n
w^\epsilon_{ij}.
\]</span></p>
<p>If calculated with Kendall’s rank correlation, Tau-BC is estimated as
the rank correlation between <span class="math inline">\(\left\{\hat\epsilon^A_1, \dots, \hat\epsilon^A_m,
\hat\epsilon^B_1, \dots, \hat\epsilon^B_n \right\}\)</span> and a dummy
coded variable <span class="math inline">\(\left\{0_1,\dots,0_m,
1_1,\dots,1_n \right\}\)</span>, with an adjustment for ties <span class="citation">(<a href="#ref-kendall1970rank" role="doc-biblioref">Kendall, 1970, p. 35</a>)</span>. Specifically,</p>
<p><span class="math display">\[
\text{Tau}_{BC}^* = \frac{1}{D} \sum_{i=1}^m \sum_{j=1}^n
w^\epsilon_{ij},
\]</span> where</p>
<p><span class="math display">\[
D = \sqrt{m \times n \times \left(\frac{(m+n)(m+n-1)}{2}-U\right)}
\]</span> and <span class="math inline">\(U\)</span> is the number of
ties between all possible pairs of observations (including pairs within
phase A, pairs within phase B, and pairs of one phase A and one phase B
data point). <span class="math inline">\(U\)</span> can be computed
as</p>
<p><span class="math display">\[
U = \sum_{i=1}^{m - 1} \sum_{j = i+1}^m I\left(\hat\epsilon^A_i =
\hat\epsilon^A_j\right) + \sum_{i=1}^{n - 1} \sum_{j = i+1}^n
I\left(\hat\epsilon^B_i = \hat\epsilon^B_j\right) + \sum_{i=1}^m
\sum_{j=1}^n I\left(\hat\epsilon^A_i = \hat\epsilon^B_j\right).
\]</span></p>
<p>We prefer and recommend to use the Tau-AB form, which divides by
<span class="math inline">\(m \times n\)</span> rather than by <span class="math inline">\(D\)</span>, because it leads to a simpler
interpretation. Furthermore, using <span class="math inline">\(D\)</span> means that <span class="math inline">\(\text{Tau}_{BC}^*\)</span> may be sensitive to
variation in phase lengths. To see this sensitivity, consider a scenario
where there are no tied values and so every value <span class="math inline">\(\left\{\hat\epsilon^A_1, \dots, \hat\epsilon^A_m,
\hat\epsilon^B_1, \dots, \hat\epsilon^B_n \right\}\)</span> is unique.
In this case, <span class="math inline">\(U = 0\)</span> and <span class="math display">\[
D = \sqrt{\frac{1}{2} m n (m + n)(m + n - 1)} = m n \sqrt{1 + \frac{m -
1}{2n} + \frac{n - 1}{2m}}.
\]</span> Thus, the denominator will always be larger than <span class="math inline">\(m n\)</span>, meaning that <span class="math inline">\(\text{Tau}_{BC}^*\)</span> will always be smaller
than <span class="math inline">\(\text{Tau}_{BC}\)</span>. Further, the
largest and smallest possible values of <span class="math inline">\(\text{Tau}_{BC}^*\)</span> will be <span class="math inline">\(\pm m n / D\)</span>, or about <span class="math inline">\(1 / \sqrt{2}\)</span> when <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> are close to equal. In contrast, the
largest and smallest possible values of <span class="math inline">\(\text{Tau}_{BC}\)</span> are always -1 and 1,
respectively.</p>
</div>
<div class="section level4">
<h4 id="standard-errors-and-confidence-intervals">Standard errors and confidence intervals<a class="anchor" aria-label="anchor" href="#standard-errors-and-confidence-intervals"></a>
</h4>
<p>The exact sampling distribution of <span class="math inline">\(\text{Tau}_{BC}^*\)</span> (Kendall, adjusted for
ties) has not been described. <span class="citation">Tarlow (<a href="#ref-tarlow2017improved" role="doc-biblioref">2017</a>)</span>
proposed to approximate its sampling variance using <span class="math display">\[
SE_{Kendall} = \sqrt{\frac{2 (1 - \text{Tau}_{BC}^2)}{m + n}},
\]</span> arguing that this would generally be conservative (in the
sense of over-estimating the true sampling error). When Tau-BC is
calculated using Kendall’s rank correlation, the SingleCaseES package
reports a standard error based on this approximation.</p>
<p>When calculated without adjustment for ties, the SingleCaseES package
takes a different approach for estimating the standard error for <span class="math inline">\(\text{Tau}_{BC}\)</span> (non-overlap), reporting
approximate standard errors and confidence intervals for <span class="math inline">\(\text{Tau}_{BC}\)</span> based on the methods
described above for <span class="math inline">\(\text{Tau}\)</span>
(non-overlap, without baseline trend correction). An important
limitation of this approach is that it does not account for the
uncertainty introduced by estimating the phase A time trend (i.e., the
uncertainty in <span class="math inline">\(\hat\beta\)</span>).</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="parametric-effect-sizes">Parametric effect sizes<a class="anchor" aria-label="anchor" href="#parametric-effect-sizes"></a>
</h2>
<div class="section level3">
<h3 id="smd">SMD<a class="anchor" aria-label="anchor" href="#smd"></a>
</h3>
<p><span class="citation">Gingerich (<a href="#ref-gingerich1984meta" role="doc-biblioref">1984</a>)</span> and <span class="citation">Busk
&amp; Serlin (<a href="#ref-serlin2015meta" role="doc-biblioref">1992</a>)</span> proposed a within-case
standardized mean difference for use in single-case designs (within-case
because it is based on the data for a single individual, rather than
across individuals). The standardized mean difference parameter <span class="math inline">\(\delta\)</span> is defined as the difference in
means between phase B and phase A, scaled by the standard deviation of
the phase A outcome distribution:</p>
<p><span class="math display">\[
\delta = \frac{\mu_B - \mu_A}{\sigma_A}.
\]</span></p>
<p>Note that <span class="math inline">\(\sigma_A\)</span> represents
<em>within-individual</em> variability only. In contrast, the SMD
applied to a between-groups design involves scaling by a measure of
between- and within-individual variability. Thus, the scale of the
within-case SMD is <em>not</em> comparable to the scale of the SMD from
a between-groups design.</p>
<p>The SMD <span class="math inline">\(\delta\)</span> can be estimated
under the assumption that the observations are mutually independent and
have constant variance within each phase. There are two ways that the
SMD, depending on whether it is reasonable to assume that the standard
deviation of the outcome is constant across phases (i.e., <span class="math inline">\(\sigma_A = \sigma_B\)</span>).</p>
<div class="section level4">
<h4 id="baseline-sd">Baseline SD<a class="anchor" aria-label="anchor" href="#baseline-sd"></a>
</h4>
<p><span class="citation">Gingerich (<a href="#ref-gingerich1984meta" role="doc-biblioref">1984</a>)</span> and <span class="citation">Busk
&amp; Serlin (<a href="#ref-serlin2015meta" role="doc-biblioref">1992</a>)</span> originally suggested scaling by
the SD from phase A only, due to the possibility of non-constant
variance across phases. Without assuming constant SDs, an estimate of
the standardized mean difference is</p>
<p><span class="math display">\[
d_A = \left(1 - \frac{3}{4m - 5}\right) \frac{\bar{y}_B -
\bar{y}_A}{s_A}.
\]</span></p>
<p>The term in parentheses is a small-sample bias correction term <span class="citation">(cf. <a href="#ref-hedges1981distribution" role="doc-biblioref">Hedges, 1981</a>; <a href="#ref-pustejovsky2018procedural" role="doc-biblioref">Pustejovsky,
2019</a>)</span>. The standard error of this estimate is calculated
as</p>
<p><span class="math display">\[
SE_{d_A} = \left(1 - \frac{3}{4m - 5}\right)\sqrt{\frac{1}{m} +
\frac{s_B^2}{n s_A^2} + \frac{d_A^2}{2(m - 1)}}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="pooled-sd">Pooled SD<a class="anchor" aria-label="anchor" href="#pooled-sd"></a>
</h4>
<p>If it is reasonable to assume that the SDs are constant across
phases, then one can use the pooled sample SD, defined as</p>
<p><span class="math display">\[
s_p = \sqrt{\frac{(m - 1)s_A^2 + (n - 1) s_B^2}{m + n - 2}}.
\]</span></p>
<p>The SMD can then be estimated as</p>
<p><span class="math display">\[
d_p = \left(1 - \frac{3}{4(m + n) - 9}\right) \frac{\bar{y}_B -
\bar{y}_A}{s_p},
\]</span></p>
<p>with approximate standard error</p>
<p><span class="math display">\[
SE_{d_A} = \left(1 - \frac{3}{4(m + n) - 9}\right)\sqrt{\frac{1}{m} +
\frac{1}{n} + \frac{d_p^2}{2(m + n - 2)}}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-1">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals-1"></a>
</h4>
<p>Whether the estimator is based on the baseline or pooled standard
deviation, an approximate confidence interval for <span class="math inline">\(\delta\)</span> is given by</p>
<p><span class="math display">\[
[d - z_{\alpha/2} \times SE_d,\quad d + z_{\alpha/2} \times SE_d].
\]</span></p>
</div>
</div>
<div class="section level3">
<h3 id="lrr">LRR<a class="anchor" aria-label="anchor" href="#lrr"></a>
</h3>
<p>The log-response ratio (LRR) is an effect size index that quantifies
the change from phase A to phase B in proportionate terms. <span class="citation">Pustejovsky (<a href="#ref-pustejovsky2015measurement" role="doc-biblioref">2015</a>)</span> proposed to use it as an effect
size index for single-case designs <span class="citation">(see also <a href="#ref-pustejovsky2018using" role="doc-biblioref">Pustejovsky,
2018</a>)</span>. The LRR is appropriate for use with outcomes on a
ratio scale—that is, where zero indicates the total absence of the
outcome. The LRR parameter is defined as</p>
<p><span class="math display">\[
\psi = \ln\left(\mu_B / \mu_A\right),
\]</span></p>
<p>The logarithm is used so that the range of the index is less
restricted.</p>
<div class="section level4">
<h4 id="lrr-decreasing-and-lrr-increasing">LRR-decreasing and LRR-increasing<a class="anchor" aria-label="anchor" href="#lrr-decreasing-and-lrr-increasing"></a>
</h4>
<p>There are two variants of the LRR <span class="citation">(<a href="#ref-pustejovsky2018using" role="doc-biblioref">Pustejovsky,
2018</a>)</span>, corresponding to whether therapeutic improvements
correspond to negative values of the index (LRR-decreasing or LRRd) or
positive values of the index (LRR-increasing or LRRi). For outcomes
measured as frequency counts or rates, LRRd and LRRi are identical in
magnitude but have opposite sign. However, for outcomes measured as
proportions (ranging from 0 to 1) or percentages (ranging from 0% to
100%), LRRd and LRRi will differ in both sign and magnitude because the
outcomes are first transformed to be consistent with the selected
direction of therapeutic improvement.</p>
</div>
<div class="section level4">
<h4 id="estimation-8">Estimation<a class="anchor" aria-label="anchor" href="#estimation-8"></a>
</h4>
<p>To account for the possibility that the sample means may be equal to
zero, even if the mean levels are strictly greater than zero, the LRR is
calculated using <em>truncated</em> sample means, given by <span class="math display">\[
\tilde{y}_A = \text{max} \left\{ \bar{y}_A, \ \frac{1}{2 D m}\right\}
\qquad \text{and} \qquad \tilde{y}_B = \text{max} \left\{ \bar{y}_B, \
\frac{1}{2 D n}\right\},
\]</span> where <span class="math inline">\(D\)</span> is a constant
that depends on the scale and recording procedure used to measure the
outcomes <span class="citation">(<a href="#ref-pustejovsky2018using" role="doc-biblioref">Pustejovsky, 2018</a>)</span>. To ensure that the
standard error of LRR is strictly positive, it is calculated using
truncated sample variances, given by <span class="math display">\[
\tilde{s}_A^2 = \text{max}\left\{s_A^2, \ \frac{1}{D^2 m^3}\right\}
\qquad \text{and} \qquad \tilde{s}_B^2 = \text{max} \left\{ s_B^2, \
\frac{1}{D^2 n^3}\right\}.
\]</span></p>
<p>A basic estimator of the LRR is then given by</p>
<p><span class="math display">\[
R_1 = \ln\left(\tilde{y}_B\right) - \ln\left(\tilde{y}_A\right).
\]</span></p>
<p>However, <span class="math inline">\(R_1\)</span> will be biased when
one or both phases include only a small number of observations. A
bias-corrected estimator is given by</p>
<p><span class="math display">\[
R_2 = \ln\left(\tilde{y}_B\right) + \frac{\tilde{s}_B^2}{2 n
\tilde{y}_B^2} - \ln\left(\tilde{y}_A\right) - \frac{\tilde{s}_A^2}{2 m
\tilde{y}_A^2}.
\]</span> The bias-corrected estimator is the default option in
SingleCaseES.</p>
</div>
<div class="section level4">
<h4 id="standard-errors-2">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors-2"></a>
</h4>
<p>Under the assumption that the outcomes in each phase are mutually
independent, an approximate standard error for <span class="math inline">\(R_1\)</span> or <span class="math inline">\(R_2\)</span> is given by</p>
<p><span class="math display">\[
SE_R = \sqrt{\frac{\tilde{s}_A^2}{m \tilde{y}_A^2} +
\frac{\tilde{s}_B^2}{n \tilde{y}_B^2}}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-2">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals-2"></a>
</h4>
<p>Under the same assumptions, an approximate confidence interval for
<span class="math inline">\(\psi\)</span> is</p>
<p><span class="math display">\[
[R - z_{\alpha / 2} \times SE_R,\quad R + z_{\alpha / 2} \times SE_R].
\]</span></p>
</div>
</div>
<div class="section level3">
<h3 id="lor">LOR<a class="anchor" aria-label="anchor" href="#lor"></a>
</h3>
<p>The log-odds ratio is an effect size index that quantifies the change
from phase A to phase B in terms of proportionate change in the odds
that a behavior is occurring <span class="citation">(<a href="#ref-pustejovsky2015measurement" role="doc-biblioref">Pustejovsky,
2015</a>)</span>. It is appropriate for use with outcomes on a
percentage or proportion scale. The LOR parameter is defined as</p>
<p><span class="math display">\[
\psi = \ln\left(\frac{\mu_B/(1-\mu_B)}{\mu_A/(1-\mu_A)}\right),
\]</span></p>
<p>where the outcomes are measured in proportions. The log odds ratio
ranges from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>, with a value of zero
corresponding to no change in mean levels.</p>
<div class="section level4">
<h4 id="estimation-9">Estimation<a class="anchor" aria-label="anchor" href="#estimation-9"></a>
</h4>
<p>To account for the possibility that the sample means may be equal to
zero or one, even if the mean levels are strictly between zero and one,
the LOR is calculated using <em>truncated</em> sample means, given
by</p>
<p><span class="math display">\[
\tilde{y}_A = \text{max} \left\{ \text{min}\left[\bar{y}_A, 1 -
\frac{1}{2 D m}\right], \frac{1}{2 D m}\right\}
\]</span> and</p>
<p><span class="math display">\[
\tilde{y}_B = \text{max} \left\{ \text{min}\left[\bar{y}_B, 1 -
\frac{1}{2 D n}\right], \frac{1}{2 D n}\right\},
\]</span></p>
<p>where <span class="math inline">\(D\)</span> is a constant that
depends on the scale and recording procedure used to measure the
outcomes <span class="citation">(<a href="#ref-pustejovsky2018using" role="doc-biblioref">Pustejovsky, 2018</a>)</span>.To ensure that the
corresponding standard error is strictly positive, it is calculated
using truncated sample variances, given by</p>
<p><span class="math display">\[
\tilde{s}_A^2 = \text{max}\left\{s_A^2, \ \frac{1}{D^2 m^3}\right\}
\qquad \text{and} \qquad \tilde{s}_B^2 = \text{max} \left\{ s_B^2, \
\frac{1}{D^2 n^3}\right\}.
\]</span></p>
<p>A basic estimator of the LOR is given by</p>
<p><span class="math display">\[
LOR_1 = \ln\left(\tilde{y}_B\right) - \ln\left(1-\tilde{y}_B\right) -
\ln\left(\tilde{y}_A\right) + \ln\left(1-\tilde{y}_A\right).
\]</span></p>
<p>However, like the LRR, this estimator will be biased when the one or
both phases include only a small number of observations. A
bias-corrected estimator of the LOR is given by</p>
<p><span class="math display">\[
LOR_2 = \ln\left(\tilde{y}_B\right) - \ln\left(1-\tilde{y}_B\right) -
\frac{\tilde{s}_B^2(2 \tilde{y}_B - 1)}{2 n_B
(\tilde{y}_B)^2(1-\tilde{y}_B)^2} - \ln\left(\tilde{y}_A\right) +
\ln\left(1-\tilde{y}_A\right) + \frac{\tilde{s}_A^2(2 \tilde{y}_A -
1)}{2 n_A (\tilde{y}_A)^2(1-\tilde{y}_A)^2}.
\]</span> This estimator uses a small-sample correction to reduce bias
when one or both phases include only a small number of observations.</p>
</div>
<div class="section level4">
<h4 id="standard-errors-3">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors-3"></a>
</h4>
<p>Under the assumption that the outcomes in each phase are mutually
independent, an approximate standard error for <span class="math inline">\(LOR\)</span> is given by</p>
<p><span class="math display">\[
SE_{LOR} = \sqrt{\frac{\tilde{s}^2_A}{n_A \tilde{y}_A^2 (1 -
\tilde{y}_A)^2} + \frac{\tilde{s}^2_B}{n_B \tilde{y}_B^2 (1 -
\tilde{y}_B)^2}}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-3">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals-3"></a>
</h4>
<p>Under the same assumption, an approximate confidence interval for
<span class="math inline">\(\psi\)</span> is</p>
<p><span class="math display">\[
[LOR - z_{\alpha / 2} \times SE_{LOR},\quad LOR + z_{\alpha / 2} \times
SE_{LOR}],
\]</span></p>
</div>
</div>
<div class="section level3">
<h3 id="lrm">LRM<a class="anchor" aria-label="anchor" href="#lrm"></a>
</h3>
<p><span class="citation">Bonett &amp; Price (<a href="#ref-bonett2020interval" role="doc-biblioref">2020b</a>)</span>
described the log ratio of medians (LRM) effect size, which can be used
to quantify the change in medians from phase A to phase B. The LRM is
the natural logarithm of the ratio of medians. This effect size is
appropriate for outcomes that are skewed or right-censored <span class="citation">(<a href="#ref-bonett2020interval" role="doc-biblioref">Bonett &amp; Price, 2020b</a>)</span>. For an
outcome where increase is desirable, the LRM parameter is defined as</p>
<p><span class="math display">\[
\lambda = \ln\left(\eta_B / \eta_A\right) = \ln(\eta_B) - \ln(\eta_A),
\]</span> where <span class="math inline">\(\eta_B\)</span> and <span class="math inline">\(\eta_A\)</span> are the population medians for
phase B and phase A, respectively. For an outcome where decrease is
desirable, the LRM parameter has the opposite sign:</p>
<p><span class="math display">\[
\lambda = \ln\left(\eta_A / \eta_B\right) = \ln(\eta_A) - \ln(\eta_B).
\]</span></p>
<div class="section level4">
<h4 id="estimation-10">Estimation<a class="anchor" aria-label="anchor" href="#estimation-10"></a>
</h4>
<p>A natural estimator of the <span class="math inline">\(\lambda\)</span> is given by</p>
<p><span class="math display">\[
LRM = \ln\left(m_B\right) - \ln\left(m_A\right),
\]</span> where <span class="math inline">\(m_B\)</span> and <span class="math inline">\(m_A\)</span> are the sample medians for phase B
and phase A, respectively. Note that the sample median might be zero for
either phase B and phase A in some single-case design data, resulting in
infinite LRM.</p>
</div>
<div class="section level4">
<h4 id="standard-errors-4">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors-4"></a>
</h4>
<p>Standard errors and confidence intervals for LRM can be obtained
under the assumption that the outcome data within each phase are
mutually independent and follow a common distribution. Using the fact
that the logarithm of the median is the same or close to the median of
the log-transformed outcomes, the standard error for <span class="math inline">\(LRM\)</span> can be calculated using the order
statistics within each phase <span class="citation">(<a href="#ref-bonett2020confidence" role="doc-biblioref">Bonett &amp;
Price, 2020a</a>)</span>. Let <span class="math display">\[
\begin{aligned}
l_A &amp;= \text{max}\left\{1, \ \frac{m}{2} - \sqrt{m}\right\}, \quad
&amp;u_A &amp;= m - l_A + 1, \\
l_B &amp;= \text{max}\left\{1, \ \frac{n}{2} - \sqrt{n}\right\}, \quad
&amp;u_B &amp;= n - l_B + 1,
\end{aligned}
\]</span> and find <span class="math display">\[
q_A = \Phi^{-1}\left(\frac{1}{2^m}\sum_{i=0}^{l_A - 1} \frac{m!}{i!(m -
i)!}\right) \quad \text{and} \quad q_B =
\Phi^{-1}\left(\frac{1}{2^n}\sum_{j=0}^{l_B - 1} \frac{n!}{j!(n -
j)!}\right).
\]</span> The standard error of LRM is then <span class="math display">\[
SE_{LRM} =
\sqrt{\left(\frac{\ln\left(y^B_{(u_B)}\right)-\ln\left(y^B_{(l_B)}\right)}{2\
q_B}\right)^2 +
\left(\frac{\ln\left(y^A_{(u_A)}\right)-\ln\left(y^A_{(l_A)}\right)}{2\
q_A}\right)^2},
\]</span> <span class="citation">(<a href="#ref-bonett2020confidence" role="doc-biblioref">Bonett &amp; Price, 2020a</a>)</span> where <span class="math inline">\(y^A_{(l_A)}, y^A_{(u_A)}\)</span> are the <span class="math inline">\(l_A\)</span> and <span class="math inline">\(u_A\)</span> order statistics of the phase A
outcomes and <span class="math inline">\(y^B_{(l_B)},
y^B_{(u_B)}\)</span> are the <span class="math inline">\(l_B\)</span>
and <span class="math inline">\(u_B\)</span> order statistics of the
phase B outcomes.</p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-4">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals-4"></a>
</h4>
<p>An approximate confidence interval for <span class="math inline">\(\lambda\)</span> is <span class="math display">\[
\left[LRM - z_{\alpha/2} \times SE_{LRM},\quad LRM + z_{\alpha/2} \times
SE_{LRM}\right],
\]</span> where <span class="math inline">\(z_{\alpha/2}\)</span> is
<span class="math inline">\(1 - \alpha/2\)</span> critical value from a
standard normal distribution.</p>
</div>
</div>
<div class="section level3">
<h3 id="pogo">PoGO<a class="anchor" aria-label="anchor" href="#pogo"></a>
</h3>
<p><span class="citation">Ferron, Goldstein, Olszewski, &amp; Rohrer (<a href="#ref-ferron2020indexing" role="doc-biblioref">2020</a>)</span>
proposed a percent of goal obtained (PoGO) effect size metric for use in
single-case designs. Let <span class="math inline">\(\gamma\)</span>
denote the goal level of behavior, which must be specified by the
analyst or researcher. Percent of goal obtained quantifies the change in
the mean level of behavior relative to the goal. The PoGO parameter
<span class="math inline">\(\theta\)</span> is defined as: <span class="math display">\[
\theta = \frac{\mu_B - \mu_A}{\gamma - \mu_A} \times 100\%.
\]</span></p>
<div class="section level4">
<h4 id="estimation-11">Estimation<a class="anchor" aria-label="anchor" href="#estimation-11"></a>
</h4>
<p>Approaches for estimation of PoGO depend on one’s assumption about
the stability of the observations in phases A and B. Under the
assumption that the observations are temporally stable, a natural
estimator of PoGO is <span class="math display">\[
PoGO = \frac{\bar{y}_B - \bar{y}_A}{\gamma - \bar{y}_A} \times 100\%.
\]</span></p>
</div>
<div class="section level4">
<h4 id="standard-errors-5">Standard errors<a class="anchor" aria-label="anchor" href="#standard-errors-5"></a>
</h4>
<p><span class="citation">Patrona, Ferron, Olszewski, Kelley, &amp;
Goldstein (<a href="#ref-patrona2022effects" role="doc-biblioref">2022</a>)</span> proposed a method for calculating
a standard error for the PoGO estimator under the assumptions that the
observations within each phase are mutually independent. The standard
error uses an approximation for the standard error of two independent,
normally distributed random variables due to <span class="citation">Dunlap &amp; Silver (<a href="#ref-dunlap1986confidence" role="doc-biblioref">1986</a>)</span>.
It is calculated as <span class="math display">\[
SE_{PoGO} = \frac{1}{\gamma - \bar{y}_A} \sqrt{\frac{s_A^2}{n_A} +
\frac{s_B^2}{n_B} + \left(\frac{\bar{y}_B - \bar{y}_A}{\gamma -
\bar{y}_A}\right)^2 \frac{s_A^2}{n_A}}.
\]</span> <span class="citation">Patrona et al. (<a href="#ref-patrona2022effects" role="doc-biblioref">2022</a>)</span>
also provided a more general approximation, which can be applied when
PoGO is estimated using regressions that control for time trends or
auto-correlation. However, these methods are not implemented in
<code>SingleCaseES</code>.</p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-5">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals-5"></a>
</h4>
<p>An approximate confidence interval for <span class="math inline">\(PoGO\)</span> is given by <span class="math display">\[
[PoGO - z_{\alpha / 2} \times SE_{PoGO},\quad PoGO + z_{\alpha / 2}
\times SE_{PoGO}],
\]</span> where <span class="math inline">\(z_{\alpha / 2}\)</span> is
the <span class="math inline">\(1 - \alpha / 2\)</span> critical value
from a standard normal distribution <span class="citation">(<a href="#ref-patrona2022effects" role="doc-biblioref">Patrona et al.,
2022</a>)</span>.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Acion2006probabilistic" class="csl-entry">
Acion, L., Peterson, J. J., Temple, S., &amp; Arndt, S. (2006). <span class="nocase">Probabilistic index: An intuitive non-parametric approach
to measuring the size of treatment effects</span>. <em>Statistics in
Medicine</em>, <em>25</em>(4), 591–602. <a href="https://doi.org/10.1002/sim.2256" class="external-link">https://doi.org/10.1002/sim.2256</a>
</div>
<div id="ref-allison1994make" class="csl-entry">
Allison, D. B., &amp; Gorman, B. S. (1994). <span>“Make things as simple
as possible, but no simpler.”</span> A rejoinder to scruggs and
mastropieri. <em>Behaviour Research and Therapy</em>, <em>32</em>(8),
885–890.
</div>
<div id="ref-bonett2020confidence" class="csl-entry">
Bonett, D. G., &amp; Price, R. M. (2020a). Confidence intervals for
ratios of means and medians. <em>Journal of Educational and Behavioral
Statistics</em>, <em>45</em>(6), 750–770.
</div>
<div id="ref-bonett2020interval" class="csl-entry">
Bonett, D. G., &amp; Price, R. M. (2020b). Interval estimation for
linear functions of medians in within-subjects and mixed designs.
<em>British Journal of Mathematical and Statistical Psychology</em>,
<em>73</em>(2), 333–346.
</div>
<div id="ref-serlin2015meta" class="csl-entry">
Busk, P. L., &amp; Serlin, R. C. (1992). Meta-analysis for single-case
research. In <em>Single-case research design and analysis (psychology
revivals)</em> (pp. 199–224). Routledge.
</div>
<div id="ref-dunlap1986confidence" class="csl-entry">
Dunlap, W. P., &amp; Silver, N. C. (1986). Confidence intervals and
standard errors for ratios of normal variables. <em>Behavior Research
Methods, Instruments, &amp; Computers</em>, <em>18</em>(5), 469–471. <a href="https://doi.org/10.3758/BF03201412" class="external-link">https://doi.org/10.3758/BF03201412</a>
</div>
<div id="ref-ferron2020indexing" class="csl-entry">
Ferron, J., Goldstein, H., Olszewski, A., &amp; Rohrer, L. (2020).
Indexing effects in single-case experimental designs by estimating the
percent of goal obtained. <em>Evidence-Based Communication Assessment
and Intervention</em>, <em>14</em>(1), 6–27. <a href="https://doi.org/10.1080/17489539.2020.1732024" class="external-link">https://doi.org/10.1080/17489539.2020.1732024</a>
</div>
<div id="ref-gingerich1984meta" class="csl-entry">
Gingerich, W. J. (1984). Meta-analysis of applied time-series data.
<em>The Journal of Applied Behavioral Science</em>, <em>20</em>(1),
71–79.
</div>
<div id="ref-Grissom2001review" class="csl-entry">
Grissom, R. J., &amp; Kim, J. J. (2001). <span class="nocase">Review of
assumptions and problems in the appropriate conceptualization of effect
size</span>. <em>Psychological Methods</em>, <em>6</em>(2), 135–146. <a href="https://doi.org/10.1037/1082-989X.6.2.135" class="external-link">https://doi.org/10.1037/1082-989X.6.2.135</a>
</div>
<div id="ref-Hanley1982meaning" class="csl-entry">
Hanley, J. A., &amp; McNeil, B. J. (1982). <span class="nocase">The
meaning and use of the area under a receiver operating characteristic
(ROC) curve</span>. <em>Radiology</em>, <em>143</em>, 29–36. <a href="https://doi.org/10.1148/radiology.143.1.7063747" class="external-link">https://doi.org/10.1148/radiology.143.1.7063747</a>
</div>
<div id="ref-hedges1981distribution" class="csl-entry">
Hedges, L. V. (1981). Distribution theory for glass’s estimator of
effect size and related estimators. <em>Journal of Educational
Statistics</em>, <em>6</em>(2), 107–128.
</div>
<div id="ref-kendall1970rank" class="csl-entry">
Kendall, M. G. (1970). <em>Rank correlation methods 4th edition</em>.
Griffin.
</div>
<div id="ref-ma2006alternative" class="csl-entry">
Ma, H.-H. (2006). An alternative method for quantitative synthesis of
single-subject researches: Percentage of data points exceeding the
median. <em>Behavior Modification</em>, <em>30</em>(5), 598–617.
</div>
<div id="ref-mee1990confidence" class="csl-entry">
Mee, R. W. (1990). Confidence intervals for probabilities and tolerance
regions based on a generalization of the mann-whitney statistic.
<em>Journal of the American Statistical Association</em>,
<em>85</em>(411), 793–800.
</div>
<div id="ref-newcombe2006confidence" class="csl-entry">
Newcombe, R. G. (2006). Confidence intervals for an effect size measure
based on the mann–whitney statistic. Part 2: Asymptotic methods and
evaluation. <em>Statistics in Medicine</em>, <em>25</em>(4), 559–573.
</div>
<div id="ref-parker2009improved" class="csl-entry">
Parker, R. I., &amp; Vannest, K. (2009). An improved effect size for
single-case research: Nonoverlap of all pairs. <em>Behavior
Therapy</em>, <em>40</em>(4), 357–367.
</div>
<div id="ref-parker2009improvement" class="csl-entry">
Parker, R. I., Vannest, K. J., &amp; Brown, L. (2009). The improvement
rate difference for single-case research. <em>Exceptional Children</em>,
<em>75</em>(2), 135–150.
</div>
<div id="ref-parker2011effect" class="csl-entry">
Parker, R. I., Vannest, K. J., &amp; Davis, J. L. (2011). Effect size in
single-case research: A review of nine nonoverlap techniques.
<em>Behavior Modification</em>, <em>35</em>(4), 303–322.
</div>
<div id="ref-parker2011combining" class="csl-entry">
Parker, R. I., Vannest, K. J., Davis, J. L., &amp; Sauber, S. B. (2011).
Combining nonoverlap and trend for single-case research: Tau-u.
<em>Behavior Therapy</em>, <em>42</em>(2), 284–299.
</div>
<div id="ref-patrona2022effects" class="csl-entry">
Patrona, E., Ferron, J., Olszewski, A., Kelley, E., &amp; Goldstein, H.
(2022). <span class="nocase">Effects of explicit vocabulary
interventions for preschoolers: An exploratory application of the <span class="nocase">Percent of Goal Obtained (PoGO)</span> effect size
metric</span>. <em>Journal of Speech, Language, and Hearing
Research</em>, <em>65</em>(12), 4821–4836. <a href="https://doi.org/10.1044/2022_JSLHR-22-00217" class="external-link">https://doi.org/10.1044/2022_JSLHR-22-00217</a>
</div>
<div id="ref-pustejovsky2015measurement" class="csl-entry">
Pustejovsky, J. E. (2015). Measurement-comparable effect sizes for
single-case studies of free-operant behavior. <em>Psychological
Methods</em>, <em>20</em>(3), 342–359.
</div>
<div id="ref-pustejovsky2018using" class="csl-entry">
Pustejovsky, J. E. (2018). Using response ratios for meta-analyzing
single-case designs with behavioral outcomes. <em>Journal of School
Psychology</em>, <em>68</em>, 99–112.
</div>
<div id="ref-pustejovsky2018procedural" class="csl-entry">
Pustejovsky, J. E. (2019). Procedural sensitivities of effect sizes for
single-case designs with dbehavioral outcome measures. <em>Psychological
Methods</em>, <em>24</em>(2), 217–235.
</div>
<div id="ref-scruggs1987quantitative" class="csl-entry">
Scruggs, T. E., Mastropieri, M. A., &amp; Casto, G. (1987). The
quantitative synthesis of single-subject research: Methodology and
validation. <em>Remedial and Special Education</em>, <em>8</em>(2),
24–33.
</div>
<div id="ref-sen1967note" class="csl-entry">
Sen, P. K. (1967). A note on asymptotically distribution-free confidence
bounds for p <span class="math inline">\(\{\)</span>x&lt; y<span class="math inline">\(\}\)</span>, based on two independent samples.
<em>Sankhy<span>ā</span>: The Indian Journal of Statistics, Series
A</em>, 95–102.
</div>
<div id="ref-Swan2018gradual" class="csl-entry">
Swan, D. M., &amp; Pustejovsky, J. E. (2018). <span class="nocase">A
Gradual Effects Model for Single-Case Designs</span>. <em>Multivariate
Behavioral Research</em>. <a href="https://doi.org/10.1080/00273171.2018.1466681" class="external-link">https://doi.org/10.1080/00273171.2018.1466681</a>
</div>
<div id="ref-tarlow2017improved" class="csl-entry">
Tarlow, K. R. (2017). An improved rank correlation effect size statistic
for single-case designs: Baseline corrected tau. <em>Behavior
Modification</em>, <em>41</em>(4), 427–467.
</div>
<div id="ref-Vargha2000critique" class="csl-entry">
Vargha, A., &amp; Delaney, H. D. (2000). <span class="nocase">A critique
and improvement of the "CL" common language effect size statistics of
McGraw and Wong</span>. <em>Journal of Educational and Behavioral
Statistics</em>, <em>25</em>(2), 101–132. <a href="https://doi.org/10.2307/1165329" class="external-link">https://doi.org/10.2307/1165329</a>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by James E. Pustejovsky, Man Chen, Daniel M. Swan.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '',
    indexName: 'SingleCaseES',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
