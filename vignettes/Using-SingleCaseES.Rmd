---
title: "Basic effect sizes calculations using SingleCaseES"
author: "Daniel M. Swan and James E. Pustejovsky"
bibliography: references.bibtex
date: "`r Sys.Date()`"
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
    toc_depth: 2 
    number_sections: true
csl: apa.csl
vignette: >
  %\VignetteIndexEntry{Basic effect sizes calculations using SingleCaseES}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
nocite: |
  @pustejovsky2015measurement, @scruggs1987quantitative
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  error = TRUE
)
```

The `SingleCaseES` package provides R functions for calculating basic, within-case effect size indices for single-case designs, including several non-overlap measures
and parametric effect size measures, and for estimating the gradual
effects model developed by [Swan and Pustejovsky
(2018)](https://doi.org/10.1080/00273171.2018.1466681). Standard errors
and confidence intervals are provided for the subset of effect sizes
indices with known sampling distributions. The available non-overlap 
indices are:

-   Percentage of non-overlapping data (PND)
-   Percentage of all non-overlapping data (PAND)
-   Robust improvement rate difference (IRD)
-   Percentage exceeding the median (PEM)
-   Non-overlap of all pairs (NAP)
-   Tau non-overlap (Tau)
-   Tau-U (including baseline trend adjustment)

The available parametric effect sizes are:

-   Within-case standardized mean difference
-   Log response ratio (decreasing and increasing)
-   Log odds ratio
-   The gradual effects model, which can be used to estimate log
    response ratios or log odds ratios in the presence of time trends
    during treatment and return-to-baseline phases.

The package also includes two graphical user interfaces (designed using
[Shiny](https://shiny.rstudio.com/)) for interactive use, both of which
are also available as web apps hosted through
[shinyapps.io](https://www.shinyapps.io/):

-   `SCD_effect_sizes()` opens an interactive calculator for the basic
    non-overlap indices and parametric effect sizes. It is also
    available at <https://jepusto.shinyapps.io/SCD-effect-sizes>
-   `shine_gem_scd()` opens an interactive calculator for the gradual
    effects model. It is also available at
    <https://jepusto.shinyapps.io/gem-scd>

# Using SingleCaseES

The first part of this vignette focuses on the calculation of non-overlap effect
sizes along with the log-response ratio, the log odds ratio, and the standardized
mean difference. The use of the gradual effects model will be examined separately.

## NAP

### A, B inputs

All of the effect sizes functions in `SingleCaseES` can take the data from a
single SCD series in one of two formats. The first format involves providing a
vector corresponding to the A phase (typically the baseline phase) and a vector 
corresponding to the B phase (typically the treatment phase).

```{r}
library(SingleCaseES)
A <- c(20, 20, 26, 25, 22, 23)
B <- c(28, 25, 24, 27, 30, 30, 29)
NAP(A_data = A, B_data = B)
```

### condition, outcome inputs

The second format involves providing a single vector of outcomes and a vector
with values corresponding to the A phase and the B phase.

```{r}
cond <- c(rep("A", 6), rep("B", 7))
outcome <- c(20, 20, 26, 25, 22, 23, 28, 25, 24, 27, 30, 30, 29)
NAP(condition = cond, outcome = outcome)
```

Note that if the provided vector for `condition` has more than two values,
the effect size function will throw an error.

```{r}
cond2 <- c(rep("A", 5), rep("B", 5), rep("C",3))
NAP(condition = cond2, outcome = outcome)
```

By default, the the effect size functions treat the first observed value of
`condition` as the the baseline phase. However, if the baseline phase is not the
first phase, you can specify the baseline phase explicitly. This might happen in
an SCD design with multiple participants comparing two different interventions and
the ordering of the interventions is alternated across participants, but you want
the effect sizes you calculate for each series to be comparable across cases. You
can specify the baseline phase using the `baseline_phase` argument.

```{r}
cond <- c(rep("B", 7), rep("A", 6))
outcome <- c(28, 25, 24, 27, 30, 30, 29,20, 20, 26, 25, 22, 23)
NAP(condition = cond, outcome = outcome, baseline_phase = "A")
```

Additionally, most of the effect size functions default to assuming that the desired
effect of the intervention is an increase in the outcome behavior. You can also 
specify a that the desired effect of the intervention is a decrease by specifying
`improvement = "decrease"` when you call the effect size argument.

```{r}
NAP(A_data = A, B_data = B, improvement = "decrease")
```

The `NAP` function has several possible methods for calculating the standard 
error. By default the exactly unbiased standard errors are used . However, the 
function can also produce standard errors using the Hanley-McNeil estimator, 
the variance under the null hypothesis of no effect, or no standard errors at all.

```{r}
NAP(A_data = A, B_data = B, SE = "unbiased")
NAP(A_data = A, B_data = B, SE = "Hanley")
NAP(A_data = A, B_data = B, SE = "null")
NAP(A_data = A, B_data = B, SE = "none")
```

Note that the confidence intervals don't depend upon the standard error 
calculations. The confidence interval calculation is controlled via the 
`confidence` argument, where the interval can be specified 0 < confidence < 1,
or set to `NULL` to calculate no confidence interval.

```{r}
NAP(A_data = A, B_data = B)
NAP(A_data = A, B_data = B, confidence = .99)
NAP(A_data = A, B_data = B, confidence = .90)
NAP(A_data = A, B_data = B, confidence = NULL)    
```

## Other effect size functions

### Non-overlap indices

As noted previously, the `SingleCaseES` package can estimate a number of 
non-overlap indices. The functions for PND (`PND()`), PAND (`PAND()`),
IRD (`IRD()`), PEM (`PEM`) and Tau-U (`Tau_U()`) all accept data in either the
A, B format or the condition, outcome format with optional baseline 
specification and the ability to specify the direction of improvement. Like the
function for NAP, the function for Tau (`Tau`) can produce unbiased standard
errors, Hanley-McNeil standard errors, standard errors under the null hypothesis 
of no effect, or no standard errors at all. The confidence level for the 
confidence intervals can also be controlled, or no confidence interval at all 
can be specified using `NULL`.

### Log-Response Ratio

The response ratio parameter is the ratio of the mean level of the outcome during
phase B to the mean level of the outcome during phase A. The log response ratio 
is the natural logarithm of the response ratio. This effect size is appropriate 
for outcomes measured on a ratio scale (so that zero corresponds to the true 
absence of the outcome.here are two versions of the LRR. The LRR-increasing (`LRRi()`) 
is defined so that positive values correspond to therapeutic improvements. The 
LRR-decreasing (`LRRd()`) is defined so that negative values correspond to therapeutic 
improvements.

If you are simply estimating an effect size for a single series, pick the one 
that corresponds to the therapeutic improvement expected by your intervention. 
Similarly, if you are estimating effect sizes for a set of SCD series with the
same therapeutic direction, pick the one that corresponds to your intervention's
expected change. If you are estimating effect sizes for interventions where the
direction of improvement depends upon the series or study, it is slightly more
involved. For example, imagine you had ten studies you wanted to meta-analyze. For
eight studies the outcome are initiations of peer interaction and the therapeutic 
direction was an increase. For the other two, the outcomes were episodes of physical
aggression, so the therapeutic direction was a decrease. In this context it would be
sensible to pick the `LRRi()` function, because most of the outcomes are 
positively-valenced. For the final two studies, you would specify `improvement = "decrease"`,
which would ensure that the sign and magnitude of the outcomes were consistent
with the direction of therapeutic improvement i.e. a larger log-ratio represents
a larger change in the desired direction. Conversely, if most of the outcomes
had a negative valence, and only a few had a positive valence, then you would
use `LRRd()` and for the few that were positively-valenced you would specify
`improvement = "increase"`.

If the outcome is a count (the default for both LRR functions) or rate , changing 
the  improvement direction merely changes the sign of the effect size.

```{r}
A <- c(20, 20, 26, 25, 22, 23)
B <- c(28, 25, 24, 27, 30, 30, 29)
LRRd(A_data = A, B_data = B)
LRRd(A_data = A, B_data = B, improvement = "increase")
```

It is also possible to specify the measurement scale of the outcome using the 
`scale` argument, with the possible choices being "count", "rate" (assumed to be 
events per minute), "percentage", "proportion" or "other. If the `scale` is 
specified as "proportion" or "percentage" then changing the improvement direction 
will alter the magnitude as well as the sign of the effect size. @pustejovsky2018using [p. 16-18] has more details.

```{r}
A <- c(20, 20, 26, 25, 22, 23)
B <- c(28, 25, 24, 27, 30, 30, 29)
LRRd(A_data = A, B_data = B, scale = "percentage")
LRRd(A_data = A, B_data = B, improvement = "increase", scale = "percentage")
```

The scale of the outcome has one more important implication. To account for the
possibility of a sample mean of zero, the function will calculate a truncated
mean if the scale of the outcome plus some additional information is provided. If
no additional information is provided and there is a sample mean of 0, the function
returns `NaN` as a result. For rates, the truncated mean requires specifying the 
length of the observation session in minutes. If a vector of observation lengths
is supplied, the mean will be used.

```{r}
A <- c(0, 0, 0, 0)
B <- c(28, 25, 24, 27, 30, 30, 29)
LRRd(A_data = A, B_data = B, scale = "rate")
LRRd(A_data = A, B_data = B, scale = "rate", observation_length = 30)
```

For outcomes specified as percentages or proportions, the argument `intervals`
must be supplied. For interval observation methods such as partial interval
recording or momentary time sampling, provide the number of intervals. For
continuous recording, set `intervals` equal to 60 times the length of the observation
session in minutes. If a vector of intervals is supplied, the mean will be used.

```{r}
LRRd(A_data = A, B_data = B, scale = "percentage")
LRRd(A_data = A, B_data = B, scale = "percentage", intervals = 180)
```

You can also specify your own value the constant used to truncate the sample
mean by supplying a value for `D_const`. If a vector, the mean will be used.

Both LRR functions return a effect size that has been bias-corrected for small
sample sizes by default. If an un-corrected effect size is desired, set
`bias_correct = FALSE`. Finally, as with non-overlap measures, `confidence`
can be used to change the default 95% confidence interval, or set to `NULL`
to omit confidence interval calculations.

### Log-Odds Ratio

The odds ratio parameter is the ratio of the odds. The log-odds ratio (LOR) is the 
natural logarithm of the odds ratio. This effect size is appropriate for 
outcomes measured on a percentage or proportion scale. The `LOR()` function works
almost identically to the `LRRi()` and `LRRd()` functions with a few exceptions. 

As with the LOR functions, the improvement direction can be specified, and the
default assumption is that a therapeutic improvement is an increase in the
behavior. Unlike  the LRRi or LRRd, the scale of the outcome must be reversed 
(e.g. `1 - proportion` or `100 -percentage`) in order to account for differences 
in valence between effect sizes. Unlike the LRR functions, it is not as simple 
as -1 times the LRR for the opposite valence.

```{r}
A_pct <- c(20, 20, 25, 25, 20, 25)
B_pct <- c(30, 25, 25, 25, 35, 30, 25)

LOR(A_data = A_pct, B_data = B_pct,
    scale = "percentage", improvement = "increase")
LOR(A_data = A_pct, B_data = B_pct,
    scale = "percentage", improvement = "decrease")
```

The `LOR()` function accepts only outcomes that are specified as proportion or 
percentage.

```{r}
LOR(A_data = A_pct, B_data = B_pct,
    scale = "percentage")

LOR(A_data = A_pct/100, B_data = B_pct/100,
    scale = "proportion")

LOR(A_data = A_pct, B_data = B_pct,
    scale = "count")
```

In fashion similar to the LRR functions, `LOR()` will produce a truncated mean
for cases where phase means are equal to zero if the number of intervals per
observation session is specified via the `intervals` argument. For continuous 
recording, use a number of intervals equal to 60 times the length of the 
observation session in minutes.

```{r}
LOR(A_data = c(0,0,0), B_data = B_pct,
   scale = "percentage")
LOR(A_data = c(0,0,0), B_data = B_pct,
    scale = "percentage", intervals = 20)
```

Like the LRR functions, it is possible to specify your own truncation constant
using the `D_const` argument. By default the `LOR()` function produces effect
sizes with a bias correction for small sample sizes, but this can be turned off
by specifying the argument `bias_correct = FALSE`. The width of the confidence
intervals is controlled via the `confidence` argument, and no confidence
intervals will be produced if the argument is set to `confidence = NULL`.

## Standardized Mean Difference

The standardized mean difference parameter is defined as the difference between 
the mean level of the outcome in phase B and the mean level of the outcome in 
phase A, scaled by the within-case standard deviation of the outcome in phase A.
As with all functions discussed so far, the `SMD()` function accepts data in both
the A_data, B_data format and the condition, outcome format with optional
baseline phase specification.

The direction of improvement can be specified with the `improvement` argument,
with "increase" being the default assumed direction of therapeutic improvement.
Changing the direction of the improvement does not change the magnitude of the
effect size, merely the direction.

```{r}
A <- c(20, 20, 26, 25, 22, 23)
B <- c(28, 25, 24, 27, 30, 30, 29)
SMD(A_data = A, B_data = B, improvement = "increase")
SMD(A_data = A, B_data = B, improvement = "decrease")
```

The `std_dev` argument controls whether the function uses just the standard 
deviation of the baseline to calculate the effect size (the default, `std_dev = "baseline"`),
or pools the standard deviation across both phases (`std_dev = "pool"`).

```{r}
SMD(A_data = A, B_data = B, std_dev = "baseline")
SMD(A_data = A, B_data = B, std_dev = "pool")
```

By default the `SMD()` function produces effect sizes with a bias correction for
small sample sizes, but this can be turned off by specifying the argument 
`bias_correct = FALSE`. The width of the confidence intervals is controlled via 
the `confidence` argument, and no confidence intervals will be produced if the 
argument is set to `confidence = NULL`.

## calc_ES()

The `SingleCaseES` package also has a function that will produce multiple effect
sizes estimates for a single SCD series, `calc_ES()`. As with the individual effect
size estimators, `calc_ES()` accepts data both in the A_data, B_data format and the
condition, outcome format with optional baseline phase specification. By 
default, the function calculates LRRd, LRRi, SMD, 
and Tau.

```{r}
A <- c(20, 20, 26, 25, 22, 23)
B <- c(28, 25, 24, 27, 30, 30, 29)
calc_ES(A_data = A, B_data = B)
phase <- c(rep("A", length(A)), rep("B", length(B)))
outcome <- c(A, B)
calc_ES(condition = phase, outcome = outcome, baseline_phase = "A")
```

The `ES` argument can be specified as a character string or character vector to
calculate a desired set of effect sizes among "LRRd", "LRRi", "LOR", "SMD", "NAP", 
"IRD", "PND", "PEM", "PAND", "Tau", and "Tau-U".

```{r}
calc_ES(A_data = A, B_data = B, ES = c("LRRd", "NAP", "PND", "PEM"))
```

Setting `ES = "all"` will return all available effect sizes, "parametric" returns
all parametric effect sizes, and "NOM" returns all non-overlap measures.

```{r}
calc_ES(A_data = A, B_data = B, ES = "parametric")
calc_ES(A_data = A, B_data = B, ES = "NOM")
calc_ES(A_data = A, B_data = B, ES = "all")
```

Details such as the measurement scale can also be passed on to functions that will
make use of them.

```{r}
calc_ES(A_data = A, B_data = B, ES = c("LRRd", "LOR", "NAP", "PND", "PEM"))
calc_ES(A_data = A, B_data = B, ES = c("LRRd", "LOR", "NAP", "PND", "PEM"), scale = "percentage")
```

The options common to all effect size functions, `improvement` and `confidence`
can be specified as well. Finally, using the `format` argument, the output
of calc_ES can be changed. The function defaults to `format = "long"`; 
`format = "wide"` will provide all output as a single line rather than one line
per effect size.

```{r, warning = FALSE}
calc_ES(A_data = A, B_data = B)
calc_ES(A_data = A, B_data = B, format = "wide")
```
## batch_calc_ES()

This section of the vignette assumes that you are already comfortable with the 
`es_calc()` function as well as the other effect size functions.

The `batch_calc_ES()` function will produce any of the previously detailed effect
sizes for multiple series. For instance for multiple participants in a study, or
for multiple participants across multiple studies. Unlike the other functions
described before, the data for `batch_calc_ES()` must be contained within a
dataframe (or datatable), with a line corresponding to a single observation
within a series, and columns corresponding to different variables (e.g. outcome,
phase, session_number). There are a number of required arguments for the function.

The argument `dat` should be the dataframe containing all of the observations 
for all of the SCDs of interest. 

The `grouping_vars` argument should be a vector of strings of the names of the
variables that uniquely identify each series. For several SCDs within a single
study, this might simply be a variable name that identifies the participant
pseudonym. If that study also contained multiple outcomes, for instance verbal
outbursts and proportion of time on task, it would be a vector containing with
the name of the variable that identifies the participant pseudonym and the
behavior type. For multiple SCDs across multiple studies you might also include
a variable name that identified the study from which each series was drawn.

The `condition` argument should be a string containing the variable name that
identifies the treatment condition for each observation in the series. The values
for the baseline and treatment phases should be uniform across all of the series
within a dataset. So if some series had "0" as baseline and "1" as treatment,
whereas other series had "A" as baseline and "B" as treatment, it would be
important to pick one or the other and clean your data appropriately before
using the `batch_calc_ES()` function.

The `outcome` argument should be a string containing the variable name that
identifies the outcome data.

The `session_number` argument should be a string containing the name of a variable
used to order the outcomes within each series.

The `baseline_phase` argument should be a character string specifying which value
of `condition` corresponds to the baseline phase. This has to be a single value,
and is why it is important to pick a single scheme for identifying baseline and
treatment phases within your dataset.

The `ES` argument allows you to specify which effect size index or indices to
calculate. It works exactly like `calc_ES()`, also allowing you to specify all
effect sizes, parametric effect sizes, or non-overlap measures.

The `improvement`, `scale`, `intervals`, and `observation_length` argument can 
works somewhat like their parallel arguments for the `calc_ES()` functions, in 
that it will accept a uniform value (such as `improvement = "decrease"` or 
`scale = "proportion"`) if all of the series within the dataset are uniform with
respect towards a particular argument. However, if the values indicated by these
arguments varies from series to series, it is also possible to specify the name 
of a variable which identifies the direction of improvement, outcome scale, number
of intervals per observation, and  length of the observation sessions. If you are
providing these inputs as variables, any series where the information is not
relevant or is not available specify it as missing (`NA`). For instance, data
gathered as a count is generally not gathered for an interval recording method,
so it would be appropriate to specify intervals as `NA` for count data.

The `...` allows for arguments particular to an individual function such as `std_dev` 
for the `SMD()` function to be passed to that function to change its default
behavior. Note that arguments common to several functions, such as `bias_correct`
cannot be specified differently for different effect size functions.

The `confidence` argument controls the confidence intervals in the same way as all
the other functions. The `format` argument defaults to "long" where each effect
size for each series and any accompanying standard errors and confidence intervals
will be returned as its own line. If the argument is set to `format = "wide"` 
then each series will have its own line with columns corresponding to effect 
sizes and any accompanying standard errors and confidence intervals.

Finally, the `warn` argument defaults to true. If you ask for the LOR effect size
and some of your series are not proportion or percentages, the function will
warn you that data specified as count, rate, or other will be returned as NA
for the LOR. You can turn off this warning by setting `warn = FALSE`.

### Some Examples

The `McKissick` dataset is data drawn from McKissick et al. (2010). These data
are event counts of negative behaviors observed at the classroom level.

```{r}
data(McKissick)

head(McKissick)
```

The data contains a pseudonym for each case (`Case_pseudonym`) corresponding to
a classroom period. It also contains a within case session number
(`Session_number`), a variable (`Condition`) corresponding to the baseline ("A")
and treatment ("B") phases. It has an outcome variable containing the values of
the outcomes, a variable specifying the length of the observation session
(`Session_length`), as well as a variable corresponding to the measurement scale
(`Procedure`). Note that the session length is uniform across all series (20),
and the measurement scale also does not vary. There are a couple of ways to
specify this using the batch calculation function.

```{r}
batch_calc_ES(dat = McKissick, grouping_vars = "Case_pseudonym", condition = "Condition",
              outcome = "Outcome", session_number = "Session_number", baseline_phase = "A",
              improvement = "decrease", scale = "Procedure", observation_length = "Session_length")

batch_calc_ES(dat = McKissick, grouping_vars = "Case_pseudonym", condition = "Condition",
              outcome = "Outcome", session_number = "Session_number", baseline_phase = "A",
              improvement = "decrease", scale = "count", observation_length = 20)

```

We can also request the effect sizes in a wide format:

```{r}
batch_calc_ES(dat = McKissick, grouping_vars = "Case_pseudonym", condition = "Condition",
              outcome = "Outcome", session_number = "Session_number", baseline_phase = "A",
              improvement = "decrease", scale = "Procedure", observation_length = "Session_length",
              format = "wide")
```

As noted, it is possible to specify arguments for requested effect sizes, such as `std_dev`
for `SMD()`.

```{r}
batch_calc_ES(dat = McKissick, grouping_vars = "Case_pseudonym", condition = "Condition",
              outcome = "Outcome", session_number = "Session_number", baseline_phase = "A",
              ES = "SMD", improvement = "decrease", scale = "Procedure", 
              observation_length = "Session_length", std_dev = "baseline")

batch_calc_ES(dat = McKissick, grouping_vars = "Case_pseudonym", condition = "Condition",
              outcome = "Outcome", session_number = "Session_number", baseline_phase = "A",
              ES = "SMD", improvement = "decrease", scale = "Procedure", 
              observation_length = "Session_length", std_dev = "pool")
```

The Schmidt2007 dataset are data drawn from Schmidt (2007). This data is somewhat
more complicated. It has two outcomes for each participant which have differing
directions of improvement, as well as different outcome measurement scales for
the two outcomes. Each series also has a baseline phase, a treatment phase,
a return to baseline phase, and a second treatment phase. We will be estimating
effect sizes for each phase pair separately.

```{r}
data(Schmidt2007)

head(Schmidt2007)
```

This demonstration will focus on a subset of the variables:
`Behavior_type` which specifies whether the outcome is disruptive behavior or on
task behavior, `Metric` which specifies whether it is percentage or count data,
`Session_length` which specifies the length of the observation session, 
`Case_Pseudonym` which specifies which participant the observation corresponds to,
`Session_number` which specifies the within-session observation ordering,
`Condition` which specifies whether the outcome is in the baseline ("A") phase
or the treatment ("B") phase, `Outcome` which contains the outcome data,
`Phase_num` which specifies whether the data is in the first or second phase
pair, `direction` which specifies the improvement direction, and `N_intervals`
which specifies the number of intervals for the percentage outcomes.

```{r}
schmidt_es <- batch_calc_ES(dat = Schmidt2007,
              grouping_vars = c("Case_pseudonym", "Behavior_type", "Phase_num"),
              condition = "Condition",
              outcome = "Outcome",
              session_number = "Session_number",
              baseline_phase = "A",
              improvemnt = "direction",
              scale = "Metric",
              intervals = "n_Intervals",
              observation_length = "Session_length")

knitr::kable(schmidt_es)
```

The output contains a row corresponding to each phase pair for each outcome type
for each participant, for each type of effect size.

# References

